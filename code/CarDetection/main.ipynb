{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8x.pt to 'yolov8x.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131M/131M [00:02<00:00, 55.5MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 9 cars, 174.6ms\n",
      "Speed: 3.0ms preprocess, 174.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[884, 473]\n",
      "[883, 473]\n",
      "[881, 473]\n",
      "[878, 473]\n",
      "\n",
      "0: 384x640 8 cars, 37.7ms\n",
      "Speed: 2.6ms preprocess, 37.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[800, 471]\n",
      "[798, 471]\n",
      "[797, 471]\n",
      "[796, 471]\n",
      "[794, 471]\n",
      "[793, 471]\n",
      "\n",
      "0: 384x640 8 cars, 36.6ms\n",
      "Speed: 2.8ms preprocess, 36.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[705, 465]\n",
      "[702, 465]\n",
      "\n",
      "0: 384x640 8 cars, 35.1ms\n",
      "Speed: 2.1ms preprocess, 35.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[651, 465]\n",
      "[650, 465]\n",
      "\n",
      "0: 384x640 8 cars, 35.6ms\n",
      "Speed: 2.0ms preprocess, 35.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[635, 470]\n",
      "\n",
      "0: 384x640 8 cars, 35.0ms\n",
      "Speed: 3.0ms preprocess, 35.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 28.2ms\n",
      "Speed: 2.5ms preprocess, 28.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[632, 472]\n",
      "\n",
      "0: 384x640 8 cars, 1 umbrella, 29.0ms\n",
      "Speed: 1.0ms preprocess, 29.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 29.1ms\n",
      "Speed: 1.0ms preprocess, 29.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[630, 471]\n",
      "\n",
      "0: 384x640 8 cars, 29.6ms\n",
      "Speed: 1.0ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[629, 471]\n",
      "\n",
      "0: 384x640 8 cars, 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 29.2ms\n",
      "Speed: 1.0ms preprocess, 29.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 26.7ms\n",
      "Speed: 2.0ms preprocess, 26.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 27.6ms\n",
      "Speed: 1.5ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 28.5ms\n",
      "Speed: 2.5ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[629, 471]\n",
      "\n",
      "0: 384x640 8 cars, 26.1ms\n",
      "Speed: 2.5ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[637, 471]\n",
      "[638, 471]\n",
      "\n",
      "0: 384x640 8 cars, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[656, 481]\n",
      "\n",
      "0: 384x640 8 cars, 29.1ms\n",
      "Speed: 3.0ms preprocess, 29.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[656, 482]\n",
      "\n",
      "0: 384x640 8 cars, 27.1ms\n",
      "Speed: 1.0ms preprocess, 27.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 28.8ms\n",
      "Speed: 2.1ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 cars, 28.2ms\n",
      "Speed: 1.0ms preprocess, 28.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "#roi 없는 버전\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import Tracker\n",
    "import numpy as np\n",
    "model = YOLO('yolov8s.pt')\n",
    "model.classes = [0, 1, 2, 3, 5, 7]\n",
    "#cap = cv2.VideoCapture('rtsp://ID:Passwd@IPIPIPIP:PORT/stream1')\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:  \n",
    "        print([x, y])\n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap = cv2.VideoCapture('./sample.mp4')\n",
    "\n",
    "with open(\"coco.txt\", \"r\") as my_file:\n",
    "    data = my_file.read()\n",
    "    class_list = data.split(\"\\n\") \n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 비디오 출력을 위한 준비\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) #v\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))#v\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') #v\n",
    "video_writer = cv2.VideoWriter('output_video.mp4', fourcc, fps, (w, h))#v\n",
    "\n",
    "scaling_factor = 0.06  # 픽셀당 실제 거리(미터)로 변경\n",
    "tracker = Tracker()\n",
    "previous_positions = {}\n",
    "previous_widths = {}\n",
    "\n",
    "speeds = {}\n",
    "frame_count = 0\n",
    "\n",
    "while True:    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "    results = model.predict(frame)\n",
    "    a = results[0].boxes.data.cpu()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "    cars = []\n",
    "\n",
    "    for index, row in px.iterrows():\n",
    "        if 'car' in class_list[int(row[5])]:\n",
    "            x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            # Only pass x, y, width, height to the tracker\n",
    "            cars.append([x1, y1, width, height]) \n",
    "\n",
    "    bbox_id = tracker.update(cars)\n",
    "\n",
    "    for bbox in bbox_id:\n",
    "        x1, y1, w, h, id = bbox\n",
    "        x2, y2 = x1 + w, y1 + h\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "        \n",
    "        if id in previous_positions:\n",
    "            prev_center, prev_width = previous_positions[id]\n",
    "            distance_pixels = np.linalg.norm(np.array((cx, cy)) - np.array(prev_center))\n",
    "        if id not in previous_positions:\n",
    "            previous_positions[id] = ((cx, cy), frame_count)\n",
    "\n",
    "        prev_center, prev_frame = previous_positions[id]\n",
    "        if frame_count - prev_frame >= 10:\n",
    "            width_ratio = width**2/ prev_width**2 if prev_width else 1\n",
    "            corrected_distance = distance_pixels / width_ratio\n",
    "            distance_pixels = ((cx - prev_center[0])**2 + (cy - prev_center[1])**2)**0.5\n",
    "            distance_meters = distance_pixels * scaling_factor\n",
    "            time_seconds = (frame_count - prev_frame) / fps\n",
    "            speed_mps = distance_meters / time_seconds\n",
    "            speed_kmph = speed_mps*3.6\n",
    "            speeds[id] = speed_kmph\n",
    "            previous_positions[id] = ((cx, cy), frame_count)\n",
    "\n",
    "        if id in speeds:\n",
    "            # Draw bbox\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            # Display speed\n",
    "            cv2.putText(frame, f\"ID: {id} Speed: {speeds[id]:.2f} km/h\", (x1, y2 - 10), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "    frame_count += 1\n",
    "    video_writer.write(frame)#v\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()#v\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import code.Server.producer\n",
    "#속도, bbox, class, roi\n",
    "\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import Tracker\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO('yolov8x.pt')\n",
    "model.classes = [0, 1, 2, 3, 5, 7]\n",
    "#cap = cv2.VideoCapture('rtsp://ID:Passwd@IPIPIPIP:PORT/stream1')\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:  \n",
    "        print([x, y])\n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "cap = cv2.VideoCapture('./sample.mp4')\n",
    "\n",
    "with open(\"coco.txt\", \"r\") as my_file:\n",
    "    data = my_file.read()\n",
    "    class_list = data.split(\"\\n\") \n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "scaling_factor = 0.06  # 픽셀당 실제 거리(미터)로 변경\n",
    "tracker = Tracker()\n",
    "previous_positions = {}\n",
    "previous_widths = {}\n",
    "\n",
    "speeds = {}\n",
    "frame_count = 0\n",
    "\n",
    "# Define the ROI coordinates (x, y, width, height)\n",
    "roi_x, roi_y, roi_w, roi_h = 750, 200, 530, 520  # Example coordinates\n",
    "\n",
    "\n",
    "# Kafka\n",
    "# 브로커와 토픽명을 지정한다.\n",
    "broker = 'localhost:9008'\n",
    "topic = 'Smart-Barricade'\n",
    "message_producer = code.Server.producer.MessageProducer(broker, topic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "    \n",
    "    roi_frame = frame[roi_y:roi_y+roi_h, roi_x:roi_x+roi_w]\n",
    "    \n",
    "    results = model.predict(roi_frame)\n",
    "    a = results[0].boxes.data.cpu()\n",
    "    px = pd.DataFrame(a).astype(\"float\")\n",
    "    cars = []\n",
    "\n",
    "    for index, row in px.iterrows():\n",
    "        if 'car' in class_list[int(row[5])]:\n",
    "            x1, y1, x2, y2 = int(row[0]), int(row[1]), int(row[2]), int(row[3])\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            x1 += roi_x\n",
    "            y1 += roi_y\n",
    "            x2 += roi_x\n",
    "            y2 += roi_y\n",
    "            \n",
    "            \n",
    "            # Only pass x, y, width, height to the tracker\n",
    "            cars.append([x1, y1, width, height])  # Update here\n",
    "\n",
    "    bbox_id = tracker.update(cars)\n",
    "\n",
    "    for bbox in bbox_id:\n",
    "        x1, y1, w, h, id = bbox\n",
    "        x2, y2 = x1 + w, y1 + h\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "        if id in previous_positions:\n",
    "            prev_center, prev_width = previous_positions[id]\n",
    "            distance_pixels = np.linalg.norm(np.array((cx, cy)) - np.array(prev_center))\n",
    "        if id not in previous_positions:\n",
    "            previous_positions[id] = ((cx, cy), frame_count)\n",
    "            \n",
    "        prev_center, prev_frame = previous_positions[id]\n",
    "        if frame_count - prev_frame >= 10:\n",
    "            width_ratio = width**2 / prev_width**2 if prev_width else 1\n",
    "            corrected_distance = distance_pixels / width_ratio\n",
    "            distance_pixels = ((cx - prev_center[0])**2 + (cy - prev_center[1])**2)**0.5\n",
    "            distance_meters = distance_pixels * scaling_factor\n",
    "            time_seconds = (frame_count - prev_frame) / fps\n",
    "            speed_mps = distance_meters / time_seconds\n",
    "            speed_kmph = speed_mps*3.6\n",
    "            speeds[id] = speed_kmph\n",
    "            previous_positions[id] = ((cx, cy), frame_count)\n",
    "\n",
    "        if id in speeds:\n",
    "            # Draw bbox\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            # Display speed\n",
    "            cv2.putText(frame, f\"ID: {id} Speed: {speeds[id]:.2f} km/h\", (x1, y2 - 10), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    cv2.rectangle(frame, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (255, 0, 0), 2)  # ROI in blue\n",
    "    frame_count += 1\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    print(\"send-data: \", frame)\n",
    "    message_producer.send_message(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
